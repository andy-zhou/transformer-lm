{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605aceae-64b9-4c07-96fc-9246628b4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src import data, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1402fb8-acf8-4c72-943a-9b0efbc3b14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "encoder, train, val = data.load(\"data/tinyshakespeare.txt\")\n",
    "print(encoder.decode(train[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a063c075",
   "metadata": {},
   "source": [
    "## Baseline: Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "054d06c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Baseline Model...\n",
      "\n",
      "Iteration      0/10000: train_loss=4.3886, val_loss=4.3794\n",
      "Iteration   2000/10000: train_loss=2.5089, val_loss=2.5211\n",
      "Iteration   4000/10000: train_loss=2.4782, val_loss=2.4982\n",
      "Iteration   6000/10000: train_loss=2.4642, val_loss=2.4858\n",
      "Iteration   8000/10000: train_loss=2.4627, val_loss=2.4820\n",
      "\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "print('Training Baseline Model...\\n')\n",
    "baseline_model = models.train_bigram_model(train, val, encoder, num_iters=10000)\n",
    "print('\\nTraining Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a84bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Baseline Generation\n",
      "---------\n",
      "\n",
      "Gorerooug ongang ir melyock---\n",
      "CI thesil on f\n",
      "As,\n",
      "I o?\n",
      "O:\n",
      "S:\n",
      "Pth. lotonoode.\n",
      "NGis-llt Cow mispllewe r a haive urd.\n",
      "FFo herert m ferqu gru hoto f findedon, e w s t hot hou ous INTovef lolisethoursesio LE:\n",
      "\n",
      "I r d\n",
      "CARDOLAyod thewareree t botewibed inde d thel nd d nous adousou ecris\n",
      "STous hour ms sear ncl the keaMathe?\n",
      "IUKIvamdy oulllle; yo alle iveas wir m herstham bulerwitedous adear:\n",
      "\n",
      "\n",
      "BUEThan e \n"
     ]
    }
   ],
   "source": [
    "print(f'Example Baseline Generation\\n---------')\n",
    "print(encoder.decode(baseline_model.generate(num_characters=400)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
